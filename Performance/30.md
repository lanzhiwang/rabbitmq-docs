# RabbitMQ, backing stores, databases and disks

https://blog.rabbitmq.com/posts/2011/01/rabbitmq-backing-stores-databases-and-disks/

*January 20, 2011*

From time to time, on our [mailing list](https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss) and elsewhere, the idea comes up of using a different *backing store* within RabbitMQ. The backing store is the bit that’s responsible for writing messages to disk (a message can be written to disk for a number of reasons) and it’s a fairly frequent suggestion to see what RabbitMQ would look like if its own backing store was replaced with another storage system.  有时，在我们的邮件列表和其他地方，会出现在 RabbitMQ 中使用不同的后备存储的想法。后备存储是负责将消息写入磁盘的位（一条消息可以出于多种原因写入磁盘），并且经常建议查看如果将其自己的后备存储替换为另一个存储，RabbitMQ 会是什么样子系统。

Such a change would permit functionality that is not currently possible, for example out-of-band queue browsing, or distributed storage, but there is a fundamental difference in the nature of data storage and access patterns between a message broker such as RabbitMQ and a generic database. Indeed RabbitMQ deliberately does not store messages in such a database.  这样的更改将允许当前无法实现的功能，例如带外队列浏览或分布式存储，但是在数据存储的性质和访问模式之间存在根本差异，例如 RabbitMQ 和消息代理通用数据库。事实上，RabbitMQ 故意不在这样的数据库中存储消息。

Firstly we need to discuss what properties RabbitMQ itself expects of any backing store. RabbitMQ writes messages to disk in two cases: either the message has been published in such a way that it must be written to disk (e.g. published with `delivery_mode = 2`) or memory pressure is causing RabbitMQ to start running out of RAM and so it is pushing messages to disk in order to free up RAM. In the first case, just because we’ve written the message to disk, does not mean that we’re going to forget about it from RAM: if memory is abundant then there’s no reason to incur the cost of a subsequent disk read.  首先，我们需要讨论 RabbitMQ 本身期望任何后备存储具有哪些属性。 RabbitMQ 在两种情况下将消息写入磁盘：消息以必须写入磁盘的方式发布（例如，使用 Delivery_mode = 2 发布）或内存压力导致 RabbitMQ 开始耗尽 RAM，因此它是将消息推送到磁盘以释放 RAM。在第一种情况下，仅仅因为我们已经将消息写入磁盘，并不意味着我们会从 RAM 中忘记它：如果内存充足，则没有理由承担后续磁盘读取的成本。

In the second case, it means that any backing store that keeps everything in RAM all the time is immediately not a good fit: RabbitMQ writes messages to disk in order to free up RAM, thus if the “writing to disk” bit actually just moves the message from one area of RAM to another without freeing up RAM then nothing has been gained. Using such a backing store might work and it might achieve the improvements in functionality desired, but such a change would have substantial impact on the scalability of RabbitMQ: it would no longer be able to absorb more messages than can be kept in RAM, which was one of the *raisons d’être* for the *new persister* work that led to RabbitMQ’s current default backing store.  在第二种情况下，这意味着任何将所有内容始终保存在 RAM 中的后备存储立即不适合：RabbitMQ 将消息写入磁盘以释放 RAM，因此如果“写入磁盘”位实际上只是移动在没有释放 RAM 的情况下从 RAM 的一个区域向另一个区域发送消息，然后什么也没有获得。使用这样的后备存储可能会起作用，并且可能会实现所需的功能改进，但是这样的更改将对 RabbitMQ 的可伸缩性产生重大影响：它将不再能够吸收比 RAM 中保存的更多的消息，这是导致 RabbitMQ 当前默认后备存储的新持久性工作的存在理由之一。

Some databases or key-value stores write disk contents by initially writing a snapshot of their entire data set, and then writing deltas to that data set. After a while, either time based or based on the number of deltas, or ratio of deltas to snapshot size, a new snapshot is written, and then the previous snapshot and all its deltas can be thrown away. This is how RabbitMQ’s *old persister* worked. The problem with this is that it can repeatedly cause vast amounts of data to be unnecessarily rewritten. Imagine you have two queues, one of which is entirely static: no one is publishing messages to it, and no one is consuming messages from it, it’s just sitting there, but it contains several million messages, all of which have been written to disk. The other queue is almost always empty, but is moving very quickly – thousands of messages a second are being published and consumed from it. Every message sent to that queue has to be written to disk, but they’re all being consumed as soon as they’ve been written to disk. Consider the effect of this scenario on the backing store: the second queue will cause a rapid stream of deltas to occur but whenever the snapshot is rewritten, it’ll cause the entire contents of the first queue to be rewritten too *even though there has been no change to that queue’s contents*. So again, backing stores that write messages to disk in this way are likely to be a poor fit for RabbitMQ’s needs.  一些数据库或键值存储通过最初写入其整个数据集的快照，然后将增量写入该数据集来写入磁盘内容。一段时间后，无论是基于时间还是基于增量数量，或者增量与快照大小的比率，都会写入一个新快照，然后可以丢弃之前的快照及其所有增量。这就是 RabbitMQ 的旧持久化器的工作方式。这样做的问题是它会反复导致大量数据被不必要地重写。假设你有两个队列，其中一个是完全静态的：没有人向它发布消息，也没有人从它消费消息，它只是坐在那里，但它包含几百万条消息，所有这些消息都已写入磁盘.另一个队列几乎总是空的，但移动得非常快——每秒有数千条消息被发布和消费。发送到该队列的每条消息都必须写入磁盘，但一旦写入磁盘，它们就会全部被使用。考虑这种情况对后备存储的影响：第二个队列将导致发生快速的增量流，但是每当重写快照时，它也会导致第一个队列的全部内容也被重写，即使已经存在该队列的内容没有变化。同样，以这种方式将消息写入磁盘的后备存储可能不适合 RabbitMQ 的需求。

So suitable backing stores (assuming the performance and scalability properties that RabbitMQ has need to be kept: this is by no means certain in all scenarios) would be able to store a volume of data bounded only by disk size rather than RAM, and also have a reasonably sophisticated means of storing data on disk such that unchanged data won’t be rewritten indefinitely.  因此，合适的后备存储（假设 RabbitMQ 需要保留的性能和可扩展性属性：这在所有情况下都不是确定的）将能够存储仅受磁盘大小而不是 RAM 限制的数据量，并且还具有一种在磁盘上存储数据的相当复杂的方法，这样未更改的数据就不会被无限期地重写。

There are a couple of further aspects of RabbitMQ’s default backing store that are worth mentioning. Queues themselves decide when and whether to write a message to disk. But a single message can be sent to multiple queues and it is obviously advantageous to make sure each message only gets written to disk once. However, there are two distinct pieces of information here: firstly, the message content itself. This is the same in every queue that the message has been sent to, and should only be written to disk once, regardless of the number of queues it goes to; note that subsequent writes of this do not need to do a value comparison: if the ID of the message is known to the backing store then the message body will match what is already on disk – message content is never altered by the broker. The second piece of information is the existence of the message in each queue: where in the queue it lies, what its neighbours are, and what its queue-specific status is. This second piece of information is what allows RabbitMQ to start up, recover messages and queues from disk and ensure that the messages in each queue are in the same order as when RabbitMQ was shut down.  RabbitMQ 的默认后备存储还有几个方面值得一提。队列本身决定何时以及是否将消息写入磁盘。但是一条消息可以发送到多个队列，确保每条消息只写入磁盘一次显然是有利的。但是，这里有两条不同的信息：首先，消息内容本身。这在消息发送到的每个队列中都是相同的，并且应该只写入磁盘一次，无论它去往多少个队列；请注意，后续写入不需要进行值比较：如果后备存储知道消息的 ID，则消息正文将匹配磁盘上已经存在的内容——消息内容永远不会被代理更改。第二条信息是每个队列中是否存在消息：它在队列中的哪个位置，它的邻居是什么，以及它的队列特定状态是什么。第二条信息允许 RabbitMQ 启动，从磁盘恢复消息和队列，并确保每个队列中的消息与 RabbitMQ 关闭时的顺序相同。

Thus RabbitMQ’s default backing store consists of a node-global *message store* which is concerned only with writing message contents to disk; and a per queue *queue index* which uses a very different format for writing per message per queue data to disk. Because these two needs are very specific, there are an awful lot of optimisations that can be applied (and we have!).  因此 RabbitMQ 的默认后备存储由一个节点全局消息存储组成，它只关心将消息内容写入磁盘；以及每个队列队列索引，它使用非常不同的格式将每个队列数据的每个消息写入磁盘。因为这两个需求非常具体，所以可以应用很多优化（我们有！）。

Generic database benchmarks normally show that read performance vastly out performs write performance. If it doesn’t then that normally means the writes aren’t actually going to disk (with `fsync`), or there’s a bug which is crippling read performance. And indeed, databases have historically been optimised for read-heavy workloads. This matches their general use case: there is a slowly expanding data set which must be queried in various different ways. Deletions tend to be quite rare: if you think about the typical website shopping basket on top of a relational database, then unless a customer deletes their account, there are very few reasons to ever issue deletions – even if a product is discontinued, you’re probably just going to set a flag on that product row because otherwise you risk stopping customers from being able to see their order history (assuming it’s normalised).  通用数据库基准测试通常表明读取性能大大优于写入性能。如果没有，那通常意味着写入实际上并没有写入磁盘（使用 fsync），或者存在一个严重影响读取性能的错误。事实上，数据库历来针对读取繁重的工作负载进行了优化。这符合他们的一般用例：有一个缓慢扩展的数据集，必须以各种不同的方式进行查询。删除往往非常罕见：如果您考虑基于关系数据库的典型网站购物篮，那么除非客户删除他们的帐户，否则很少有理由发布删除 - 即使产品停产，您re 可能只是要在该产品行上设置一个标志，否则您可能会阻止客户查看他们的订单历史记录（假设它已正常化）。

So the vast volume of data in most databases is fairly static. This is the exact opposite of data in message brokers: for us, *reading* data is the rarest operation, and *writing* and *deleting* data are the common cases. Ideally, if RabbitMQ is running in plenty of memory, there will never be any reads from disk at all. There will only be writes for messages that are published in such a way that they have to be written to disk, and even then, provided we can get the message out to a consumer quickly enough, there are many ways in which we can optimise out those writes. We only ever read data when memory pressure has forced us to write messages to disk and then forget about the message from RAM. Read performance is certainly important: we work hard to make sure RabbitMQ gets rid of data as fast as possible (without utilising `/dev/null`) and being able to read messages from disk quickly is part of that. But avoiding the write in the first place is the goal.  因此，大多数数据库中的大量数据是相当静态的。这与消息代理中的数据完全相反：对我们来说，读取数据是最稀有的操作，写入和删除数据是常见的情况。理想情况下，如果 RabbitMQ 在大量内存中运行，则根本不会从磁盘读取任何内容。只有以必须写入磁盘的方式发布的消息才会写入，即使这样，只要我们能够足够快地将消息发送给消费者，我们可以通过多种方式优化那些写。只有当内存压力迫使我们将消息写入磁盘然后忘记来自 RAM 的消息时，我们才会读取数据。读取性能当然很重要：我们努力确保 RabbitMQ 尽可能快地删除数据（不使用 /dev/null）并且能够快速从磁盘读取消息是其中的一部分。但首先避免写入是目标。

In fact, as far as message brokers are concerned, it’s best to think of RAM as a large write-back cache for the disk, and then the task is to optimise the management of this cache to maximise the elimination of writes by delaying them for as long as possible in the hope that the corresponding deletion occurs before the write has really gone to disk. This is quite obviously very different from normal databases which do not try to make gains from the lifespan of data being so short as it frequently is in a message broker.  实际上，就消息代理而言，最好将 RAM 视为磁盘的大型回写缓存，然后任务就是优化对这个缓存的管理，通过延迟写入来最大限度地消除写入尽可能长的希望在写入真正进入磁盘之前发生相应的删除。这显然与普通数据库非常不同，普通数据库不会试图从数据的生命周期中获得收益，因为它经常在消息代理中。

None of this is meant to deter efforts to make RabbitMQ work with alternative backing stores, but merely to explain why we decided to do our own thing when writing the *new persister* for RabbitMQ (which first came out with RabbitMQ version 2.0.0) rather than use an off-the-shelf data store. It explains why building a high performance message broker directly on top of a normal database is tricky at best, and why the nature of data in a message broker is very different from the nature of data in a database.  这些都不是为了阻止使 RabbitMQ 与替代后备存储一起工作的努力，而只是为了解释为什么我们决定在为 RabbitMQ 编写新的持久化器时做自己的事情（它首先与 RabbitMQ 版本 2.0.0 一起出现）而不是使用现成的数据存储。它解释了为什么直接在普通数据库之上构建高性能消息代理充其量是棘手的，以及为什么消息代理中数据的性质与数据库中数据的性质大不相同。


