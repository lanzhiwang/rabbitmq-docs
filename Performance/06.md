# New Credit Flow Settings on RabbitMQ 3.5.5

https://blog.rabbitmq.com/posts/2015/10/new-credit-flow-settings-on-rabbitmq-3-5-5

In order to prevent fast publishers from overflowing the broker with more messages than it can handle at any particular moment, RabbitMQ implements an internal mechanism called **credit flow** that will be used by the various systems inside RabbitMQ to throttle down publishers, while allowing the message consumers to catch up. In this blog post we are going to see how **credit flow** works, and what we can do to tune its configuration for an optimal behaviour.  为了防止快速发布者在任何特定时刻处理过多的消息使代理溢出，RabbitMQ 实现了一种称为信用流的内部机制，RabbitMQ 内部的各种系统将使用该机制来限制发布者，同时允许消息消费者赶上。 在这篇博文中，我们将了解信用流是如何工作的，以及我们可以做些什么来调整其配置以获得最佳行为。

The [latest](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_5_5) version of RabbitMQ includes a couple of new configuration values that let users fiddle with the internal credit flow settings. Understanding how these work according to your particular workload can help you get the most out of RabbitMQ in terms of performance, but beware, increasing these values *just to see what happens* can have adverse effects on how RabbitMQ is able to respond to message bursts, affecting the internal strategies that RabbitMQ has in order to deal with memory pressure. **Handle with care**.  RabbitMQ 的最新版本包括几个新的配置值，让用户可以摆弄内部信用流设置。 根据您的特定工作负载了解这些如何工作可以帮助您在性能方面充分利用 RabbitMQ，但请注意，增加这些值只是为了看看会发生什么可能会对 RabbitMQ 如何响应消息突发产生不利影响，影响 RabbitMQ 处理内存压力的内部策略。 小心轻放。

To understand the new credit flow settings first we need to understand how the internals of RabbitMQ work with regards to message publishing and paging messages to disk. Let’s see first how message publishing works in RabbitMQ.  要了解新的信用流设置，首先我们需要了解 RabbitMQ 的内部在消息发布和将消息分页到磁盘方面是如何工作的。 我们先来看看消息发布在 RabbitMQ 中是如何工作的。

## Message Publishing

To see how `credit_flow` and its settings affect publishing, let’s see how internal messages flow in RabbitMQ. Keep in mind that RabbitMQ is implemented in Erlang, where processes communicate by sending messages to each other.  要了解 credit_flow 及其设置如何影响发布，让我们看看 RabbitMQ 中的内部消息是如何流动的。 请记住，RabbitMQ 是在 Erlang 中实现的，其中进程通过相互发送消息进行通信。

Whenever a RabbitMQ instance is running, there are probably hundreds of Erlang processes exchanging messages to communicate with each other. We have for example **a reader process** that reads AMQP frames from the network. Those frames are transformed into AMQP commands that are forwarded to the AMQP **channel process**. If this channel is handling a publish, it needs to ask a particular exchange for the list of queues where this message should end up going, which means the channel will deliver the message to each of those **queues**. Finally if the AMQP message needs to be persisted, the **msg_store process** will receive it and write it to disk. So whenever we publish an AMQP message to RabbitMQ we have the following erlang message flow:  每当 RabbitMQ 实例运行时，可能有数百个 Erlang 进程交换消息以相互通信。 例如，我们有一个从网络读取 AMQP 帧的读取器进程。 这些帧被转换成 AMQP 命令，然后转发到 AMQP 通道进程。 如果这个通道正在处理一个发布，它需要向一个特定的交换器询问这个消息最终应该去哪里的队列列表，这意味着该通道将把消息传递给每个队列。 最后，如果 AMQP 消息需要持久化，msg_store 进程将接收它并将其写入磁盘。 因此，每当我们向 RabbitMQ 发布 AMQP 消息时，我们都会有以下 erlang 消息流：

```
reader -> channel -> queue process -> message store.
```

In order to prevent any of those processes from overflowing the next one down the chain, we have a *credit flow* mechanism in place. Each process initially grants certain amount of credits to the process that it’s sending them messages. Once a process is able to handle N of those messages, it will grant more credit to the process that sent them. Under default *credit flow* settings (**credit_flow_default_credit** under rabbitmq.config) these values are 200 messages of initial credit, and after 50 messages processed by the receiving process, the process that sent the messages will be granted 50 more credits.  为了防止这些流程中的任何一个溢出链中的下一个流程，我们有一个信用流机制。 每个进程最初都会向它发送消息的进程授予一定数量的信用。 一旦一个进程能够处理这些消息中的 N 个，它就会向发送它们的进程授予更多的信用。 在默认信用流设置（rabbitmq.config 下的credit_flow_default_credit）下，这些值为200 条初始信用消息，在接收进程处理50 条消息后，发送消息的进程将获得50 多条信用。

Say we are publishing messages to RabbitMQ, this means the *reader* will be sending one erlang message to the channel process per AMQP `basic.publish` received. Each of those messages will consume one of these credits from the channel. Once the channel is able to process 50 of those messages, it will grant more credit to the reader. So far so good.  假设我们要向 RabbitMQ 发布消息，这意味着读取器将向每个接收到的 AMQP basic.publish 的通道进程发送一条 erlang 消息。 这些消息中的每一个都将消耗来自频道的这些信用之一。 一旦通道能够处理其中的 50 条消息，它将授予读者更多的信用。 到现在为止还挺好。

In turn the channel will send the message to the queue process that matched the message routing rules. This will consume one credit from the credit granted by the queue process to the channel. After the queue process manages to handle 50 deliveries, it will grant 50 more credits to the channel.  反过来，通道将消息发送到匹配消息路由规则的队列进程。 这将从队列进程授予通道的信用中消耗一个信用。 在队列进程设法处理 50 次交付后，它将向通道授予 50 多个信用。

Finally if a message is deemed to be persistent (it’s persistent and published to a durable queue), it will be sent to the message store, which in this case will also consume credits from the ones granted by the message store to the queue process. In this case the initial values are different and handled by the **msg_store_credit_disc_bound** setting: **2000** messages of initial credit and **500** more credits after 500 messages are processed by the message store.  最后，如果一条消息被认为是持久的（它是持久的并发布到持久队列），它将被发送到消息存储，在这种情况下，它还将消耗消息存储授予队列进程的信用。 在这种情况下，初始值不同并由 msg_store_credit_disc_bound 设置处理：2000 条初始信用的消息和 500 条消息由消息存储处理后的 500 多条信用。

So we know how internal messages flow inside RabbitMQ and when credit is granted to a process that’s above in the msg stream. The tricky part comes when credit is granted between processes. Under normal conditions a channel will process 50 messages from the reader, and then grant the reader 50 more credits, but keep in mind that a channel is not just handling publishes, it’s also sending messages to consumers, routing messages to queues and so on.  所以我们知道内部消息如何在 RabbitMQ 中流动，以及何时将信用授予 msg 流中的上述进程。 棘手的部分是在流程之间授予信用时。 在正常情况下，通道会处理来自阅读器的 50 条消息，然后再授予阅读器 50 个信用，但请记住，通道不仅处理发布，它还向消费者发送消息，将消息路由到队列等。

What happens if the reader is sending messages to the channel at a higher speed of what the channel is able to process? If we reach this situation, then the channel will block the reader process, which will result in producers being throttled down by RabbitMQ. Under default settings, the reader will be blocked once it sends 200 messages to the channel, but the channel is not able to process at least 50 of them, in order to grant credit back to the reader.  如果阅读器以比通道能够处理的速度更快的速度向通道发送消息，会发生什么？ 如果我们遇到这种情况，那么通道将阻塞读取器进程，这将导致生产者被 RabbitMQ 限制。 在默认设置下，一旦读取器向通道发送 200 条消息，就会被阻止，但通道无法处理至少 50 条消息，以便将信用返还给读取器。

Again, under normal conditions, once the channel manages to go through the message backlog, it will grant more credit to the reader, but there’s a catch. What if the channel process is being blocked by the queue process, due to similar reasons? Then the **new credit** that was supposed to go to the reader process **will be deferred**. The reader process **will remain blocked**.  同样，在正常情况下，一旦通道设法通过消息积压，它将授予读者更多的信用，但有一个问题。 由于类似的原因，如果通道进程被队列进程阻塞了怎么办？ 然后，本应进入读者进程的新信用将被推迟。 读取器进程将保持阻塞状态。

Once the queue process manages to go through the deliveries backlog from the channel, it will grant more credit to the channel, unblocking it, which will result in the channel granting more credit to the reader, unblocking it. Once again, that’s under normal conditions, but, you guessed it, what if the message store is blocking the queue process? Then credit to the channel will be deferred, which will remain blocked, deferring credit to the reader, **leaving the reader blocked**. At some point, the message store will grant messages to the queue process, which will grant messages back to the channel, and then the channel will finally grant messages to the reader and **unblock the reader**:  一旦队列进程设法通过通道的交付积压，它将授予通道更多的信用，解除阻塞，这将导致通道授予阅读器更多的信用，解除阻塞。 再一次，这是在正常情况下，但是，你猜对了，如果消息存储阻塞了队列进程怎么办？ 然后对通道的信用将被推迟，这将保持阻塞，推迟对读者的信用，使读者被阻塞。 在某个时刻，消息存储将向队列进程授予消息，队列进程将向通道授予消息，然后通道最终将向阅读器授予消息并解除对阅读器的阻塞：

```
reader <--[grant]-- channel <--[grant]-- queue process <--[grant]-- message store.
```

Having one channel and one queue process makes things easier to undertand but it might not reflect reality. It’s common for RabbitMQ users to have more than one channel publishing messages on the same connection. Even more common is to have one message being routed to more than one queue. What happens with the credit flow scheme we’ve just explained is that **if one of those queues blocks the channel**, then **the reader will be blocked as well**.  拥有一个通道和一个队列过程使事情更容易理解，但它可能无法反映现实。 RabbitMQ 用户在同一个连接上有多个通道发布消息是很常见的。 更常见的是将一条消息路由到多个队列。 我们刚刚解释的信用流方案会发生什么，如果这些队列之一阻塞了通道，那么读取器也将被阻塞。

The problem is that from a reader standpoint, when we read a frame from the network, we don’t even know to which channel it belongs to. Keep in mind that channels are a logical concept on top of AMQP connections. So even if a new AMQP command will end up in a channel that is not blocking the reader, the reader has no way of knowing it. Note that **we only block publishing** connections, consumers connections are unaffected since we want consumers to drain messages from queues. This is a good reason why it might be better to have connections dedicated to publishing messages, and connections dedicated for consumers only.  问题在于，从读者的角度来看，当我们从网络中读取一个帧时，我们甚至不知道它属于哪个通道。 请记住，通道是 AMQP 连接之上的一个逻辑概念。 所以即使一个新的 AMQP 命令最终会进入一个没有阻塞阅读器的通道，阅读器也无法知道它。 请注意，我们只阻止发布连接，消费者连接不受影响，因为我们希望消费者从队列中排出消息。 这是一个很好的理由，为什么最好有专用于发布消息的连接和专用于消费者的连接。

On a similar fashion, whenever a channel is processing message publishes, it doesn’t know where messages will end up going, until it performs routing. So a channel might be receiving a message that should end up in a queue that is not blocking the channel. Since at ingress time we don’t know any of this, then the credit flow strategy in place is to block the reader until processes down the chain are able to handle new messages.  以类似的方式，每当通道处理消息发布时，它不知道消息最终会去哪里，直到它执行路由。 因此，一个通道可能正在接收一条消息，该消息应该在一个不会阻塞该通道的队列中结束。 由于在入口时我们对此一无所知，因此适当的信用流策略是阻止读取器，直到链下的进程能够处理新消息。

One of the new settings introduced in RabbitMQ 3.5.5 is the ability to modify the values for `credit_flow_default_credit`. This setting takes a tuple of the form `{InitialCredit, MoreCreditAfter}`. InitialCredit is set to **200** by default, and MoreCreditAfter is set to **50**. Depending on your particular workflow, you need to decide if it’s worth bumping those values. Let’s see the message flow scheme again:  RabbitMQ 3.5.5 中引入的新设置之一是能够修改 credit_flow_default_credit 的值。 此设置采用 {InitialCredit, MoreCreditAfter} 形式的元组。 InitialCredit 默认设置为 200，MoreCreditAfter 设置为 50。根据您的特定工作流程，您需要决定是否值得增加这些值。 我们再来看看消息流方案：

```
reader -> channel -> queue process -> message store.
```

Bumping the values for `{InitialCredit, MoreCreditAfter}` will mean that at any point in that chain we could end up with more messages than those that can be handled by the broker at that particular point in time. More messages means more RAM usage. The same can be said about `msg_store_credit_disc_bound`, but keep in mind that there’s only one message store per RabbitMQ instance, and there can be **many channels** sending messages to the **same queue process**. So while a queue process has a value of 2000 as `InitialCredit` from the message store, that queue can be ingesting many times that value from different channel/connection sources. So 200 credits as initial `credit_flow_default_credit` value could be seen as too conservative, but you need to understand if according to your workflow that’s still good enough or not.  增加 {InitialCredit, MoreCreditAfter} 的值将意味着在该链中的任何一点，我们最终可能会收到比代理在该特定时间点可以处理的消息更多的消息。 更多的消息意味着更多的 RAM 使用。 msg_store_credit_disc_bound 也可以这样说，但请记住，每个 RabbitMQ 实例只有一个消息存储，并且可以有多个通道向同一个队列进程发送消息。 因此，虽然队列进程的值 2000 作为来自消息存储的 InitialCredit，但该队列可以从不同的通道/连接源中多次摄取该值。 所以 200 credits 作为初始 credit_flow_default_credit 值可能被视为过于保守，但您需要了解根据您的工作流程是否仍然足够好。

## Message Paging

Let’s take a look at how RabbitMQ queues store messages. When a message enters the queue, the queue needs to determine if the message should be persisted or not. If the message has to be persisted, then RabbitMQ will do so right away. Now even if a message was persisted to disk, this doesn’t mean the message got removed from RAM, since RabbitMQ keeps a cache of messages in RAM for fast access when delivering messages to consumers. Whenever we are talking about *paging messages out to disk*, we are talking about what RabbitMQ does when it has to send messages from this cache to the file system.  我们来看看 RabbitMQ 队列是如何存储消息的。 当消息进入队列时，队列需要判断该消息是否应该持久化。 如果消息必须被持久化，那么 RabbitMQ 会立即这样做。 现在，即使消息被持久化到磁盘，这并不意味着消息从 RAM 中删除，因为 RabbitMQ 将消息缓存保存在 RAM 中，以便在将消息传递给消费者时快速访问。 每当我们谈论将消息分页到磁盘时，我们都在谈论 RabbitMQ 在必须将消息从该缓存发送到文件系统时会做什么。

When RabbitMQ decides it needs to page messages to disk it will call the function `reduce_memory_use` on the internal queue implementation in order to send messages to the file system. Messages are going to be paged out in batches; how big are those batches depends on the current memory pressure status. It basically works like this:  当 RabbitMQ 决定需要将消息分页到磁盘时，它将调用内部队列实现上的 reduce_memory_use 函数，以便将消息发送到文件系统。 消息将分批调出； 这些批次有多大取决于当前的内存压力状态。 它基本上是这样工作的：

The function `reduce_memory_use` will receive a number called `target ram count` which tells RabbitMQ that it should try to page out messages until only that many remain in RAM. Keep in mind that whether messages are persistent or not, they are still kept in RAM for fast delivery to consumers. Only when memory pressure kicks in, is when messages in memory are paged out to disk. Quoting from our code comments: The question of whether a message is in RAM and whether it is persistent are orthogonal.  函数reduce_memory_use 将接收一个称为target ram count 的数字，它告诉RabbitMQ 它应该尝试分页出消息，直到只有这些消息留在RAM 中。 请记住，无论消息是否持久，它们仍然保存在 RAM 中以便快速传递给消费者。 只有当内存压力开始时，内存中的消息才会被分页到磁盘。 引用我们的代码注释： 消息是否在 RAM 中以及它是否持久的问题是正交的。

The number of messages that are accounted for during this chunk calculation are those messages that are in RAM (in the aforementioned cache), plus the number of pending acks that are kept in RAM (i.e.: messages that were delivered to consumers and are pending acknowledgment). If we have 20000 messages in RAM (cache + pending acks) and then `target ram count` is set to 8000, we will have to page out 12000 messages. This means paging will receive a quota of 12000 messages. Each message paged out to disk will consume one unit from that quota, whether it’s a pending ack, or an actual message from the cache.  在此块计算期间考虑的消息数量是 RAM 中的那些消息（在上述缓存中），加上保留在 RAM 中的待处理确认的数量（即：传递给消费者并等待确认的消息） ）。 如果我们在 RAM 中有 20000 条消息（缓存 + 未决确认），然后目标 ram 计数设置为 8000，我们将不得不分页出 12000 条消息。 这意味着寻呼将收到 12000 条消息的配额。 分页到磁盘的每条消息都将消耗该配额中的一个单位，无论是未决的 ack，还是来自缓存的实际消息。

Once we know how many messages need to be paged out, we need to decide from where we should page them first: pending acks, or the message cache. If pending acks is growing faster than messages the cache, ie: more messages are being delivered to consumers than those being ingested, this means the algorithm will try to page out pending acks first, and then try to push messages from the cache to the file system. If the cache is growing faster than pending acks, then messages from the cache will be pushed out first.  一旦我们知道需要分页出多少消息，我们就需要决定我们应该首先从哪里分页它们：待处理确认或消息缓存。 如果挂起的 ack 比缓存中的消息增长得更快，即：传递给消费者的消息多于被摄取的消息，这意味着算法将首先尝试分页出挂起的 ack，然后尝试将消息从缓存推送到文件 系统。 如果缓存的增长速度快于待处理的 ack，那么来自缓存的消息将首先被推出。

The catch here is that paging messages from pending acks (or the cache if that comes first) might result in the first part of the process consuming all the quota of messages that need to be pushed to disk. So if pending acks pushes 12000 acks to disk as in our example, this means we won’t page out messages from the cache, and vice versa.  这里的问题是，来自未决确认（或缓存，如果先出现）的分页消息可能会导致进程的第一部分消耗需要推送到磁盘的所有消息配额。 因此，如果在我们的示例中待处理的 ack 将 12000 个 ack 推送到磁盘，这意味着我们不会从缓存中分页消息，反之亦然。

This first part of the paging process sent to disk certain amount of messages (between acks + messages paged from the cache). The messages that were paged out just had their contents paged out, but their position in the queue is still in RAM. Now the queue needs to decide if this extra information that’s kept in RAM needs to be paged out as well, to further reduce memory usage. Here is were finally **msg_store_io_batch_size** enters into play (coupled with `msg_store_credit_disc_bound` as well). Let’s try to understand how they work.  分页过程的第一部分将一定数量的消息发送到磁盘（在 acks + 从缓存中分页的消息之间）。 被调出的消息只是将其内容调出，但它们在队列中的位置仍在 RAM 中。 现在队列需要决定是否需要将保存在 RAM 中的这些额外信息也调出，以进一步减少内存使用。 这是最终 msg_store_io_batch_size 发挥作用（与 msg_store_credit_disc_bound 一起使用）。 让我们试着了解它们是如何工作的。

The settings for `msg_store_credit_disc_bound` affect how internal credit flow is handled when sending message to disk. The `rabbitmq_msg_store` module implements a database that takes care of persisting messages to disk. Some details about the why’s of this implementation can be found here: [RabbitMQ, backing stores, databases and disks](https://blog.rabbitmq.com/posts/2011/01/rabbitmq-backing-stores-databases-and-disks).  msg_store_credit_disc_bound 的设置会影响将消息发送到磁盘时内部信用流的处理方式。 rabbitmq_msg_store 模块实现了一个负责将消息持久化到磁盘的数据库。 可以在此处找到有关此实现原因的一些详细信息：RabbitMQ、后备存储、数据库和磁盘。

The message store has a credit system for each of the clients that send writes to it. Every RabbitMQ queue would be a read/write client for this store. The message store has a credits mechanism to prevent a particular writer to overflow its inbox it with messages. Assuming current default values, when a writer starts talking to the message store, it receives an initial credit of **2000** messages, and it will receive more credit once **500** messages are processed. When is this credit consumed then? Credit is consumed whenever we write to the message store, but that doesn’t happen for every message. The plot thickens.  消息存储为每个向其发送写入的客户端都有一个信用系统。 每个 RabbitMQ 队列都是这个存储的读/写客户端。 消息存储有一个信用机制来防止特定的作者用消息溢出它的收件箱。 假设当前的默认值，当写入者开始与消息存储交谈时，它会收到 2000 条消息的初始信用，一旦处理了 500 条消息，它将获得更多信用。 那么这个信用什么时候消耗呢？ 每当我们写入消息存储时都会消耗信用，但并不是每条消息都会发生这种情况。 情节变厚了。

Since version 3.5.0 it’s possible to embed small messages into the queue index, instead of having to reach the message store for that. **Messages that are smaller than a configurable setting (currently 4096 bytes) will go to the queue index when persisted**, so those messages won’t consume this credit. Now, let’s see what happens with messages that do need to go to the message store.  从 3.5.0 版本开始，可以将小消息嵌入到队列索引中，而不必为此访问消息存储。 小于可配置设置（当前为 4096 字节）的消息在持久化时将进入队列索引，因此这些消息不会消耗此信用。 现在，让我们看看确实需要进入消息存储的消息会发生什么。

Whenever we publish a message that’s determined to be persistent (persistent messages published to a durable queue), then that message will consume one of these credits. If a message has to paged out to disk from the cache mentioned above, it will also consume one credit. So if during message paging we consume more credits than those currently available for our queue, the first half of the paging process might stop, since there’s no point in sending writes to the message store when it won’t accept them. This means that from the initial quota of 12000 that we would have had to page out, we only managed to process 2000 of them (assuming all of them need to go to the message store).  每当我们发布一条确定为持久的消息（发布到持久队列的持久消息）时，该消息将消耗这些信用之一。 如果一条消息必须从上面提到的缓存中调出到磁盘，它也将消耗一个信用。 因此，如果在消息分页期间我们消耗的积分比队列当前可用的积分多，则分页过程的前半部分可能会停止，因为当消息存储不接受写入时，将写入发送到消息存储是没有意义的。 这意味着，从我们必须调出的 12000 个初始配额中，我们只设法处理了其中的 2000 个（假设所有这些都需要转到消息存储）。

So we managed to page out 2000 messages, but we still keep their position in the queue in RAM. Now the paging process will determine if it needs to also page out any of these messages positions to disk as well. RabbitMQ will calculate how many of them can stay in RAM, and then it will try to page out the remaining of them to disk. **For this second paging to happen, the amount of messages that has to be paged to disk must be greater than `msg_store_io_batch_size`. The bigger this number is, the more message positions RabbitMQ will keep in RAM**, so again, depending on your particular workload, you need to tune this parameter as well.  所以我们设法分页出 2000 条消息，但我们仍然保持它们在 RAM 中的队列中的位置。 现在，分页过程将确定是否还需要将这些消息位置中的任何一个也分页到磁盘。 RabbitMQ 会计算其中有多少可以保留在 RAM 中，然后它会尝试将剩余的分页到磁盘。 要进行第二次分页，必须分页到磁盘的消息量必须大于 msg_store_io_batch_size。 该数字越大，RabbitMQ 将在 RAM 中保留的消息位置越多，因此同样，根据您的特定工作负载，您还需要调整此参数。

Another thing we improved significantly in 3.5.5 is the performance of paging queue index contents to disk. If your messages are generally smaller than **queue_index_embed_msgs_below**, then you’ll see the benefit of these changes. These changes also affect how message positions are paged out to disk, so you should see improvements in this area as well. So while having a low `msg_store_io_batch_size` might mean the queue index will have more work paging to disk, keep in mind this process has been optimized.  我们在 3.5.5 中显着改进的另一件事是将页面队列索引内容分页到磁盘的性能。 如果您的消息通常小于 queue_index_embed_msgs_below，那么您将看到这些更改的好处。 这些更改还会影响将消息位置调出到磁盘的方式，因此您也应该会看到这方面的改进。 因此，虽然 msg_store_io_batch_size 较低可能意味着队列索引将有更多的工作分页到磁盘，但请记住，此过程已得到优化。

## Queue Mirroring

To keep the descriptions above a bit simpler, we avoided bringing queue mirroring into the picture. Credit flows also affects mirroring from a channel point of view. When a channel delivers AMQP messages to queues, it sends the message to each mirror, consuming one credit from each mirror process. If any of the mirrors is slow processing the message then that particular mirror might be responsible for the channel being blocked. If the channel is being blocked by a mirror, and that queue mirror gets partitioned from the network, then the channel will be unblocked only after RabbitMQ detects the mirror death.  为了让上面的描述更简单一些，我们避免将队列镜像带入图片中。 从渠道的角度来看，信用流量也会影响镜像。 当通道将 AMQP 消息传递到队列时，它会将消息发送到每个镜像，从每个镜像进程消耗一个信用。 如果任何镜像处理消息的速度很慢，那么该特定镜像可能会导致通道被阻塞。 如果通道被镜像阻塞，并且该队列镜像被从网络分区，那么只有在 RabbitMQ 检测到镜像死亡后，通道才会被解除阻塞。

Credit flow also takes part when synchronising mirrored queues, but this is something you shouldn’t care too much about, mostly because there’s nothing you could do about it, since mirror synchronisation is handled entirely by RabbitMQ.  同步镜像队列时信用流也会参与，但这是你不应该太在意的事情，主要是因为你无能为力，因为镜像同步完全由RabbitMQ处理。

## Conclusion

In any case, we hope this blog post has been informative and helps you with your RabbitMQ tuning. If you have comments or questions about the new credit flow settings, don’t hesitate to contact us at the RabbitMQ mailing list: [rabbitmq-users](https://groups.google.com/forum/#!forum/rabbitmq-users).  无论如何，我们希望这篇博文能够提供信息并帮助您进行 RabbitMQ 调优。 如果您对新的信用流设置有意见或疑问，请随时通过 RabbitMQ 邮件列表与我们联系：rabbitmq-users。

------

1. [A message can be delivered to more than one queue process](https://blog.rabbitmq.com/posts/2015/10/new-credit-flow-settings-on-rabbitmq-3-5-5#fnref:1)  一条消息可以传递给多个队列进程。

2. [There are two message stores, one for transient messages and one for persistent messages.](https://blog.rabbitmq.com/posts/2015/10/new-credit-flow-settings-on-rabbitmq-3-5-5#fnref:2)  有两种消息存储，一种用于临时消息，一种用于持久消息。

3. [RabbitMQ will call fsync every 200 ms.](https://blog.rabbitmq.com/posts/2015/10/new-credit-flow-settings-on-rabbitmq-3-5-5#fnref:3)  RabbitMQ 将每 200 毫秒调用一次 fsync。

