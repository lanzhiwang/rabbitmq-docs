# Runtime Tuning

https://www.rabbitmq.com/runtime.html

## Overview

RabbitMQ runs on the [Erlang virtual machine](https://erlang.org/) and runtime. A [compatible version of Erlang](https://www.rabbitmq.com/which-erlang.html) must be installed in order to run RabbitMQ.  RabbitMQ 在 Erlang 虚拟机和运行时上运行。 必须安装兼容版本的 Erlang 才能运行 RabbitMQ。

The Erlang runtime includes a number of components used by RabbitMQ. The most important ones as far as this guide is concerned are  Erlang 运行时包含许多 RabbitMQ 使用的组件。 就本指南而言，最重要的是

- The Erlang virtual machine executes the code  Erlang虚拟机执行代码

- epmd resolves node names on a host to an [inter-node communication port](https://www.rabbitmq.com/networking.html)  epmd 将主机上的节点名称解析为节点间通信端口

This guide will focus on the virtual machine. For an overview of epmd, please refer to the [Networking guide](https://www.rabbitmq.com/networking.html#epmd-inet-dist-port-range).  本指南将重点介绍虚拟机。 有关 epmd 的概述，请参阅网络指南。

Topics covered include:  涵盖的主题包括：

- How to [configure Erlang VM settings for RabbitMQ](https://www.rabbitmq.com/runtime.html#vm-settings) nodes  如何为 RabbitMQ 节点配置 Erlang VM 设置

- [Runtime schedulers](https://www.rabbitmq.com/runtime.html#scheduling), what they are, how they relate to CPU cores, and so on  运行时调度程序，它们是什么，它们与 CPU 内核的关系等等

- Runtime [thread activity metrics](https://www.rabbitmq.com/runtime.html#thread-stats): where is scheduler and CPU time spent  运行时线程活动指标：调度程序和 CPU 时间在哪里花费

- Runtime features that affect [CPU utilisation](https://www.rabbitmq.com/runtime.html#cpu)  影响 CPU 利用率的运行时功能

- How to [reduce CPU utilisation](https://www.rabbitmq.com/runtime.html#cpu-reduce-idle-usage) on moderately or lightly loaded nodes  如何降低中等或轻负载节点上的 CPU 利用率

- [Memory allocator](https://www.rabbitmq.com/runtime.html#allocators) settings  内存分配器设置

- [Open file handle limit](https://www.rabbitmq.com/runtime.html#open-file-handle-limit)  打开文件句柄限制

- [Inter-node communication buffer](https://www.rabbitmq.com/runtime.html#distribution-buffer) size  节点间通信缓冲区大小

- [Erlang process limit](https://www.rabbitmq.com/runtime.html#erlang-process-limit)  Erlang 进程限制

## VM Settings  虚拟机设置

The Erlang VM has a broad range of [options that can be configured](https://erlang.org/doc/man/erl.html) that cover process scheduler settings, memory allocation, garbage collection, I/O, and more. Tuning of those flags can significantly change runtime behavior of a node.  Erlang VM 具有广泛的可配置选项，包括进程调度程序设置、内存分配、垃圾收集、I/O 等。调整这些标志可以显着改变节点的运行时行为。

### Configuring Flags  配置标志

Most of the settings can be configured using [environment variables](https://www.rabbitmq.com/configure.html#supported-environment-variables). A few settings have dedicated variables, others can only be changed using the following generic variables that control what flags are passed by RabbitMQ startup scripts to the Erlang virtual machine.  大多数设置都可以使用环境变量进行配置。一些设置具有专用变量，其他设置只能使用以下通用变量来更改，这些通用变量控制 RabbitMQ 启动脚本将哪些标志传递给 Erlang 虚拟机。

The generic variables are  通用变量是

- RABBITMQ_SERVER_ERL_ARGS allows all VM flags to be overridden, including the defaults set by RabbitMQ scripts
RABBITMQ_SERVER_ERL_ARGS 允许覆盖所有 VM 标志，包括 RabbitMQ 脚本设置的默认值

- RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS allows a set of flags to be appended to the defaults set by RabbitMQ scripts
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 允许将一组标志附加到 RabbitMQ 脚本设置的默认值

- RABBITMQ_CTL_ERL_ARGS controls [CLI tool](https://www.rabbitmq.com/cli.html) VM flags
RABBITMQ_CTL_ERL_ARGS 控制 CLI 工具 VM 标志

In most cases RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS is the recommended option. It can be used to override defaults in a safe manner. For example, if an important flag is omitted from RABBITMQ_SERVER_ERL_ARGS, runtime performance characteristics or system limits can be unintentionally affected.  在大多数情况下，RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 是推荐的选项。它可用于以安全的方式覆盖默认值。例如，如果 RABBITMQ_SERVER_ERL_ARGS 中省略了一个重要标志，则可能会无意中影响运行时性能特征或系统限制。

As with other environment variables used by RabbitMQ, RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS and friends can be [set using a separate environment variable file](https://www.rabbitmq.com/configure.html#customise-environment).  与 RabbitMQ 使用的其他环境变量一样，可以使用单独的环境变量文件设置 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 和朋友。

## CPU Utilisation  CPU 利用率

CPU utilisation is a workload-specific topic. Generally speaking, when a workload involves more queues, connections and channels than CPU cores, all cores will be used without any configuration necessary.  CPU 利用率是特定于工作负载的主题。一般来说，当工作负载涉及的队列、连接和通道多于 CPU 内核时，将使用所有内核，而无需任何配置。

The runtime provides several features that control how the cores are used.  运行时提供了几个控制内核使用方式的功能。

### Runtime Schedulers  运行时调度程序

Schedulers in the runtime assign work to kernel threads that perform it. They execute code, perform I/O, execute timers and so on. Schedulers have a number of settings that can affect overall system performance, CPU utilisation, latency and other runtime characteristics of a node.  运行时中的调度程序将工作分配给执行它的内核线程。它们执行代码、执行 I/O、执行计时器等等。调度程序有许多设置可以影响整体系统性能、CPU 利用率、延迟和节点的其他运行时特性。

By default the runtime will start one scheduler for one CPU core it detects. Starting with Erlang 23, this [takes CPU quotas into account](http://blog.erlang.org/OTP-23-Highlights/) in containerized environments such as Docker and Kubernetes.  默认情况下，运行时将为它检测到的一个 CPU 内核启动一个调度程序。从 Erlang 23 开始，这会在 Docker 和 Kubernetes 等容器化环境中考虑 CPU 配额。

The number of schedulers can be explicitly set using the +S flag. The following example configures the node to start 4 schedulers even if it detects more cores to be available to it:  可以使用 +S 标志显式设置调度程序的数量。以下示例将节点配置为启动 4 个调度程序，即使它检测到有更多内核可用：

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+S 4:4"
```

Most of the time the default behaviour works well. In shared or CPU constrained environments (including containerised ones), explicitly configuring scheduler count may be necessary.  大多数情况下，默认行为运作良好。在共享或 CPU 受限环境（包括容器化环境）中，可能需要显式配置调度程序计数。

### CPU Resource Contention  CPU 资源争用

The runtime assumes that it does not share CPU resources with other tools or tenants. When that's the case, the scheduling mechanism used can become very inefficient and result in significant (up to several orders of magnitude) latency increase for certain operations.  运行时假定它不与其他工具或租户共享 CPU 资源。在这种情况下，使用的调度机制可能会变得非常低效，并导致某些操作的延迟显着增加（高达几个数量级）。

This means that in most cases colocating RabbitMQ nodes with other tools or applying CPU time slicing is highly discouraged and will result in suboptimal performance.  这意味着在大多数情况下，非常不鼓励将 RabbitMQ 节点与其他工具并置或应用 CPU 时间切片，并且会导致性能欠佳。

### Scheduler Busy Waiting  调度程序忙等待

The runtime can put schedulers to sleep when they run out of work to execute. There's a certain cost to bringing them back online, so with some workloads it may be beneficial to not do that.  运行时可以在调度程序执行完工作时使它们进入睡眠状态。将它们重新上线需要一定的成本，因此对于某些工作负载，不这样做可能是有益的。

This can be compared to a factory with multiple conveyor belts. When one belt runs out of items, it can be stopped. However, once more work is there for it to do, restarting it will take time. Alternatively the conveyor can be speculatively kept running for a period of time.  这可以与拥有多条传送带的工厂进行比较。当一条皮带用完物品时，它可以停止。但是，一旦有更多工作要做，重新启动它需要时间。或者，输送机可以推测性地保持运行一段时间。

By default, RabbitMQ nodes configure runtime schedulers to speculatively wait for a short period of time before going to sleep. Workloads where there can be prolonged periods of inactivity can choose to disable this speculative busy waiting using the [+sbwt and related runtime flags](https://erlang.org/doc/man/erl.html):  默认情况下，RabbitMQ 节点将运行时调度程序配置为在进入睡眠之前推测性地等待一小段时间。可能存在长时间不活动的工作负载可以选择使用 +sbwt 和相关运行时标志来禁用这种推测性繁忙等待：

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+sbwt none +sbwtdcpu none +sbwtdio none"
```

This can also reduce CPU usage on systems with limited or burstable CPU resources.  这还可以减少 CPU 资源有限或可突增的系统上的 CPU 使用率。

In order to determine how much time schedulers spend in busy wait, consult [thread activity metrics](https://www.rabbitmq.com/runtime.html#thread-stats). Busy waiting will usually be accounted as system time in the output of tools such as top and pidstat.  为了确定调度程序在忙等待中花费了多少时间，请查阅线程活动指标。忙等待通常会在 top 和 pidstat 等工具的输出中计入系统时间。

### Scheduler-to-CPU Core Binding  调度程序到 CPU 核心绑定

The number of schedulers won't always match the number of CPU cores available and the number of CPU cores does not necessarily correlate to the number of hardware threads (due to hyperthreading, for example). As such the runtime has to decide how to bind scheduler binding to hardware threads, CPU cores and NUMA nodes.  调度程序的数量并不总是与可用的 CPU 内核数量相匹配，并且 CPU 内核的数量不一定与硬件线程的数量相关（例如，由于超线程）。因此，运行时必须决定如何将调度程序绑定绑定到硬件线程、CPU 内核和 NUMA 节点。

There are several binding strategies available. Desired strategy can be specified using the RABBITMQ_SCHEDULER_BIND_TYPE environment variable or using the [+stbt runtime flag](http://erlang.org/doc/man/erl.html) value.  有几种可用的绑定策略。可以使用 RABBITMQ_SCHEDULER_BIND_TYPE 环境变量或使用 +stbt 运行时标志值指定所需的策略。

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+stbt nnts"
RABBITMQ_SCHEDULER_BIND_TYPE="nnts"
```

Note that the strategy will only be effective if the runtime can detect CPU topology in the given environment.  请注意，该策略仅在运行时可以检测给定环境中的 CPU 拓扑时才有效。

Valid values are:  有效值为：

- db (used by default, alias for tnnps in current Erlang release series)
- tnnps
- nnts
- nnps
- ts
- ps
- s
- ns

See [VM flag documentation](http://erlang.org/doc/man/erl.html) for more detailed descriptions.  有关更详细的说明，请参阅 VM 标志文档。

### Reducing CPU Usage for "Moderately Idle" Nodes and Clusters  减少“中等空闲”节点和集群的 CPU 使用率

CPU usage is by definition very workload-dependent metric. Some workloads naturally use more CPU resources. Others use [disk-heavy features such as quorum queues](https://blog.rabbitmq.com/posts/2020/04/quorum-queues-and-why-disks-matter/), and if disk I/O throughput is insufficient, CPU resources will be wasted while nodes are busy waiting for I/O operations to complete.  根据定义，CPU 使用率是非常依赖于工作负载的指标。一些工作负载自然会使用更多的 CPU 资源。其他的则使用仲裁队列等重磁盘功能，如果磁盘 I/O 吞吐量不足，则会在节点忙于等待 I/O 操作完成时浪费 CPU 资源。

A couple of general recommendations can be applied to "moderately loaded" systems where a large percentage or most connections and queues can go idle from time to time. Put differently, in this section we consider any system that's not hovering around its peak capacity to be "moderately loaded".  可以将一些一般性建议应用于“中等负载”系统，在这些系统中，大部分或大多数连接和队列可能不时处于空闲状态。换句话说，在本节中，我们将任何未在其峰值容量附近徘徊的系统视为“中等负载”。

Such system often can reduce their CPU footprint with a few straightforward steps. These recommendations can significantly decrease CPU footprint with some workloads: consider [this community case for example](https://groups.google.com/forum/#!msg/rabbitmq-users/6jGtaHINmNM/rc1rR1PqAwAJ).  这样的系统通常可以通过几个简单的步骤来减少它们的 CPU 占用。这些建议可以显着减少某些工作负载的 CPU 占用：例如，考虑这个社区案例。

#### Collect Runtime Thread Statistics  收集运行时线程统计信息

Collect [runtime thread activity stats](https://www.rabbitmq.com/runtime.html#thread-stats) data to understand how scheduler and CPU time is spent. This is a critically important step for making informed decisions.  收集运行时线程活动统计数据以了解调度程序和 CPU 时间的使用情况。这是做出明智决策的关键步骤。

#### Disable Speculative Scheduler Busy Waiting  禁用推测调度程序忙等待

Disable speculative [scheduler busy waiting](https://www.rabbitmq.com/runtime.html#busy-waiting) using the [+sbwt and related runtime flags](https://erlang.org/doc/man/erl.html):  使用 +sbwt 和相关运行时标志禁用推测调度程序忙等待：

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+sbwt none +sbwtdcpu none +sbwtdio none"
```

Speculative busy waiting usually not productive on moderately loaded systems.  在中等负载的系统上，推测性的忙等待通常不会产生效果。

#### Reduce Statistics Emission Frequency (Increase the Statistics Emission Interval)  减少统计信息排放频率（增加统计信息排放间隔）

Increase [statistics emission interval](https://www.rabbitmq.com/management.html#statistics-interval) from default 5 seconds to 15 or 30 seconds. This will reduce periodic activity that all connections, channels and queues carry out, even if they would otherwise be idle as far as client operations go. With most monitoring tools such [monitoring frequency](https://www.rabbitmq.com/monitoring.html#monitoring-frequency) would be sufficient or even optimal.  将统计信息发送间隔从默认的 5 秒增加到 15 或 30 秒。这将减少所有连接、通道和队列执行的周期性活动，即使它们在客户端操作中处于空闲状态。对于大多数监控工具，这样的监控频率就足够了，甚至是最佳的。

## Thread Statistics: How is Scheduler and CPU Time Spent?  线程统计：调度程序和 CPU 时间是如何花费的？

RabbitMQ CLI tools provide a number of [metrics](https://www.rabbitmq.com/monitoring.html) that make it easier to reason about runtime thread activity.  RabbitMQ CLI 工具提供了许多指标，可以更轻松地推断运行时线程活动。

```bash
rabbitmq-diagnostics runtime_thread_stats
```

is the command that produces a breakdown of how various threads spend their time.  是生成各种线程如何花费时间的细分的命令。

The command's output will produce a table with percentages by thread activity:  该命令的输出将生成一个按线程活动百分比的表格：

- emulator: general code execution
- port: external I/O activity (socket I/O, file I/O, subprocesses)
- gc: performing garbage collection
- check_io: checking for I/O events
- other, aux: busy waiting, managing timers, all other tasks
- sleep: sleeping (idle state)

Significant percentage of activity in the external I/O state may indicate that the node and/or clients have maxed out network link capacity. This can be confirmed by [infrastructure metrics](https://www.rabbitmq.com/monitoring.html).  外部 I/O 状态中活动的显着百分比可能表明节点和/或客户端已达到网络链路容量的最大值。 这可以通过基础设施指标来确认。

Significant percentage of activity in the sleeping state might indicate a lightly loaded node or suboptimal runtime scheduler configuration for the available hardware and workload.  处于睡眠状态的活动的显着百分比可能表明节点负载较轻或可用硬件和工作负载的运行时调度程序配置欠佳。

## Memory Allocator Settings  内存分配器设置

The runtime manages (allocates and releases) memory. Runtime memory management is a complex topic with [many tunable parameters](http://erlang.org/doc/man/erts_alloc.html). This section only covers the basics.  运行时管理（分配和释放）内存。运行时内存管理是一个具有许多可调参数的复杂主题。本节仅涵盖基础知识。

Memory is allocated in blocks from areas larger pre-allocated areas called carriers. Settings that control carrier size, block size, memory allocation strategy and so on are commonly referred to as allocator settings.  内存是从称为载体的较大预分配区域的块中分配的。控制载体大小、块大小、内存分配策略等的设置通常称为分配器设置。

Depending on the allocator settings used and the workload, RabbitMQ can experience [memory fragmentation](https://en.wikipedia.org/wiki/Fragmentation_(computing)) of various degrees. Finding the best fit for your workload is a matter of trial, measurement (metric collection) and error. Note that some degree of fragmentation is inevitable.  根据使用的分配器设置和工作负载，RabbitMQ 可能会遇到不同程度的内存碎片。找到最适合您的工作负载是一个试验、测量（度量收集）和错误的问题。请注意，一定程度的碎片是不可避免的。

Here are the allocator arguments used by default:  以下是默认使用的分配器参数：

```bash
RABBITMQ_DEFAULT_ALLOC_ARGS="+MBas ageffcbf +MHas ageffcbf +MBlmbcs 512 +MHlmbcs 512 +MMmcs 30"
```

Instead of overriding RABBITMQ_DEFAULT_ALLOC_ARGS, add flags that should be overridden to RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS. They will take precedence over the default ones. So a node started with the following RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS value  不要覆盖 RABBITMQ_DEFAULT_ALLOC_ARGS，而是将应该覆盖的标志添加到 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS。它们将优先于默认值。所以一个节点以以下 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 值开始

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+MHlmbcs 8192"
```

will use in the following effective allocator settings:  将在以下有效分配器设置中使用：

```bash
"+MBas ageffcbf +MHas ageffcbf +MBlmbcs 512 +MHlmbcs 8192 +MMmcs 30"
```

For some workloads a larger preallocated area reduce allocation rate and memory fragmentation. To configure the node to use a preallocated area of 1 GB, add +MMscs 1024 to VM startup arguments using RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS:  对于某些工作负载，较大的预分配区域会降低分配率和内存碎片。要将节点配置为使用 1 GB 的预分配区域，请使用 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 将 +MMscs 1024 添加到 VM 启动参数：

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+MMscs 1024"
```

The value is in MB. The following example will preallocate a larger, 4 GB area:  该值以 MB 为单位。以下示例将预分配一个更大的 4 GB 区域：

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+MMscs 4096"
```

To learn about other available settings, see [runtime documentation on allocators](http://erlang.org/doc/man/erts_alloc.html).  要了解其他可用设置，请参阅有关分配器的运行时文档。

## Open File Handle Limit  打开文件句柄限制

Most operating systems limit the number of file handles that can be opened at the same time. When an OS process (such as RabbitMQ's Erlang VM) reaches the limit, it won't be able to open any new files or accept any more TCP connections.  大多数操作系统限制可以同时打开的文件句柄的数量。当操作系统进程（例如 RabbitMQ 的 Erlang VM）达到限制时，它将无法打开任何新文件或接受更多 TCP 连接。

This limit is covered in detail in the [Networking guide](https://www.rabbitmq.com/networking.html#open-file-handle-limit). Note that it cannot be configured using Erlang VM flags.  网络指南中详细介绍了此限制。请注意，它不能使用 Erlang VM 标志进行配置。

## Inter-node Communication Buffer Size  节点间通信缓冲区大小

Inter-node traffic between a pair of nodes uses a TCP connection with a buffer known as the inter-node communication buffer. Its size is 128 MB by default. This is a reasonable default for most workloads. In some environments inter-node traffic can be very heavy and run into the buffer's capacity. Other workloads where the default is not a good fit involve transferring very large (say, in hundreds of megabytes) messages that do not fit into the buffer.  一对节点之间的节点间通信使用带有称为节点间通信缓冲区的缓冲区的 TCP 连接。默认情况下，其大小为 128 MB。对于大多数工作负载来说，这是一个合理的默认值。在某些环境中，节点间流量可能非常大，并且会耗尽缓冲区的容量。默认值不适合的其他工作负载涉及传输不适合缓冲区的非常大（例如，数百兆字节）的消息。

In this case the value can be increased using the RABBITMQ_DISTRIBUTION_BUFFER_SIZE environment variable or the [+zdbbl VM flag](http://erlang.org/doc/man/erl.html). The value is in kilobytes:  在这种情况下，可以使用 RABBITMQ_DISTRIBUTION_BUFFER_SIZE 环境变量或 +zdbbl VM 标志来增加该值。该值以千字节为单位：

```bash
RABBITMQ_DISTRIBUTION_BUFFER_SIZE=192000
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+zdbbl 192000"
```

When the buffer is hovering around full capacity, nodes will [log](https://www.rabbitmq.com/logging.html) a warning mentioning a busy distribution port (busy_dist_port):  当缓冲区在满容量附近徘徊时，节点将记录一个警告，提到一个繁忙的分发端口（busy_dist_port）：

```bash
2019-04-06 22:48:19.031 [warning] <0.242.0> rabbit_sysmon_handler busy_dist_port <0.1401.0>
```

Increasing buffer size may help increase throughput and/or reduce latency.  增加缓冲区大小可能有助于增加吞吐量和/或减少延迟。

## Erlang Process Limit    Erlang 进程限制

The runtime has a limit on the number of Erlang processes ("lightweight threads") that can exist on a node. The default is about 1 million. In most environments this is sufficient with a wide safety margin.  运行时对节点上可以存在的 Erlang 进程（“轻量级线程”）的数量有限制。 默认值约为 100 万。 在大多数环境中，这对于较宽的安全裕度就足够了。

Environments that have a particularly [high number of concurrent connections](https://www.rabbitmq.com/networking.html#tuning-for-large-number-of-connections) or a very large number of queues (say, hundreds of thousands) this limit might need adjusting. This is done using the RABBITMQ_MAX_NUMBER_OF_PROCESSES environment variable, which is a convenient way of setting the +P Erlang VM flag:  在并发连接数量特别多或队列数量非常多（例如数十万）的环境中，此限制可能需要调整。 这是使用 RABBITMQ_MAX_NUMBER_OF_PROCESSES 环境变量完成的，这是设置 +P Erlang VM 标志的便捷方式：

```bash
RABBITMQ_MAX_NUMBER_OF_PROCESSES=2000000
```

To set the flag directly, use the RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS environment variable:  要直接设置标志，请使用 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 环境变量：

```bash
RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS="+P 2000000"
```

## Getting Help and Providing Feedback

If you have questions about the contents of this guide or any other topic related to RabbitMQ, don't hesitate to ask them on the [RabbitMQ mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users).

## Help Us Improve the Docs <3

If you'd like to contribute an improvement to the site, its source is [available on GitHub](https://github.com/rabbitmq/rabbitmq-website). Simply fork the repository and submit a pull request. Thank you!

